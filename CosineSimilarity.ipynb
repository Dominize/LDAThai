{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# การเปรียบเทียบข้อความด้วยวิธีการหา Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity เป็นการแปลงข้อความเรา ให้เป็น Vector ของตัวเลขเพื่อใช้เปรียบเทียบความเหมือนและความต่างของข้อความ ซึ่งในที่นี้เราจะใช้ Packages ได้แก้ nltk string และ sklearn ครับ\n",
    "\n",
    "** การคำนวณในที่นี้ได้วิธีการจากกระทู้นี้ครับ https://stackoverflow.com/questions/8897593/similarity-between-two-text-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หลังจาก import package แล้ว หากเราไม่เคยใช้ Package มาก่อนเลย ก็จะต้องลง Package punkt ซึ่งเป็นส่วนย่อยของ nltk เสียก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dominize\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หลังจากนั้น เราจะสร้างตัวแปลงคำศัพท์ภาษาอังกฤษให้เป็นรากศัพท์ (Stemword) ด้วยการสร้าง Function stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ต่อมาเป็นการสร้าง Function normalize สำหรับแปลงขอความให้อยู่ในลักษณะที่ไม่มีเครื่องหมายวรรคตอนและเป็นตัวพิมพ์เล็กทั้งหมด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ขั้นตอนสุดท้ายคือการสร้าง Term Frequency - Inverse Document Frequency (TF-IDF) และเปรียบเทียบข้อความด้วย Function cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สำหรับการใช้งาน เพียงแค่ส่งข้อความเข้าไปเปรียบเทียบกันสองชุดว่ามีความเหมือนกันมากน้อยเพียงใด ในรูปแบบเดียวกับ code ด้านล่าง โดยยิ่งค่าเข้าใกล้ 1 แปลว่าข้อความมีความเหมือนกันมาก ซึ่งข้อความด้านล่างมีความเหมือนกันอยู่ที่ 57% ครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57973867153766567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(\"There's nothing you can do that can't be done\",\"Nothing you can make that can't be made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "อย่างไรก็ตาม วิธีคำนวนนี้ไม่ได้คำนึงถึงลำดับของคำในข้อความแต่เป็นการวัดว่าข้อความใช้คำเหมือนหรือต่างกันอย่างไรบ้าง เพราะฉะนั้นหากเรามีสองประโยคที่ใช้คำเหมือนกันทุกประการแบบนี้ ก็จะได้ค่า Cosine Similarity ใกล้เคียงกับ 1 อย่างที่เห็นครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999978"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim('All you need is love','Love is all you need')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุดท้ายนี้ขอขอบคุณเพลง All you need is love สำหรับตัวอย่างดี ๆ และหวังว่าจะเป็นประโยชน์กับทุกคนครับ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
